---
layout: post
title: "数据挖掘之天池总结"
categories: MachineLearning
tags:   datamining machineLearning conclusion
author: Edward
---

* content
{:toc}

考试考了一周，又加班了一段时间，好久没更博客了，最近看了一下天池上一些优胜的大神的解说技巧，拿来总结一番。

--------------------

## 一、 数据分析

包括：
- 数据的记录数
- 各个字段的基本统计量 
- 测试集的各个字段占训练集的个数

## 二、数据集的划分

- 一般情况下，使用k折交叉验证就好
- 对于时间序列的问题，我们需要考虑数据穿越、特征穿越的问题，常常使用滑窗

## 三、候选集的构建

- 结合 规则 KNN 采样
- 考虑 正负样本比 样本覆盖率

## 四、特征工程

### 1、缺失值填充

- 特征为连续值，且为正态分布，使用均值填充，保持期望不变
- 特征为连续值，且为长尾分布，使用中值填充，避免异常点异常
- 特征为离散值，使用众数填充
- 使用模型预测，完善用户画像

### 2、特征变换

- 对长尾分布的特征，做对数变换
- 标准化、归一化
- 连续值特征离散化

LR、SVM、DNN等对特征的分布和尺度是比较敏感，归一化有助于模型收敛；
基于树的模型，具有伸缩不变性，不需要做特征变换

### 3、ID类特征的处理

- OneHot编码
- 使用每种类别的某些统计量代替该特征
- Word Embedding，将高维稀疏特征映射为低维稠密特征

### 4、业务特征

- 用户特征、内容特征、历史流水、上下文信息
- 使用 概率 LCS 离散化 距离 方向 比例 等统计量

tsfresh自动提取时间序列 会花费很多时间

层次化时间序列特征提取方法：
- 时间窗划分特征：最大、最小、均值、分位数
- 差分统计特征：连续值、对比(增长率)
- 转化特征：频域分析、序列变换
- 分解特征：季节性、周期性、趋势性

外界因素：
- 天气、节假日等

## 五、模型选择和验证

- 对于高维稀疏型特征，使用线性模型LR、FM算法
- 对于低维稠密型特征，使用集成树模型XGboost、GBDT、Random Forest
- 对于图像、语音等感官型数据，使用DNN，如CNN、LSTM

为什么大部分数据挖掘比赛是集成树模型XGBoost取胜？
比赛数据的特点：
结构化的表单数据
混合类型
大量缺失值
含有离群点建模
长尾分布
树算法的特点：
善于处理混合类型特征
善于处理缺失值
伸缩不变性
对离群点鲁棒
容易并行化
有高效的开源工具

## 六、模型融合

- Averaging，Voting，Stacking，Blending，Bagging
- 构建多个子模型：不同参数 不同算法 不同特征 不同视角 不同数据

## 七、评测指标：
- 准确率、召回率、F1值、ROC、AUC、PRC、mape平均绝对百分误差等
AUC评测(正负样本比不平衡时使用)

## 八、其他

- 特征使用MapReduce做
- 大数据集不需要关注调参
- 技巧：掌握泄漏

