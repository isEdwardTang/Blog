---
layout: post
title: "机器学习六之聚类"
categories: MachineLearning
tags:   datamining machineLearning clustering
author: Edward
---

* content
{:toc}

聚类任务是指在无监督学习中，通过对无标记的训练样本学习来将其划分为若干个通常是不相交的子集，即簇(cluster)，每个簇都可能对应一些潜在的概念(类别)。


--------------------

## 一、聚类度量

### 1、性能度量

聚类效果好要求簇内相似度高且簇间相似度低。聚类性能度量有两类，外部指标和内部指标，外部指标表示将聚类结果和某个参考模型进行比较，内部指标直接考察聚类结果。

a表示集合包含在聚类划分的簇，也包含参考模型的簇的样本对，b表示包含在聚类划分的簇，不包含参考模型的簇的样本对，c表示不在聚类划分的簇，包含在参考模型的簇的样本对，d表示都不包含。则定义一些性能度量外部指标有以下：

- Jaccard参数(Jaccard Cofficient，简称JC):

![Jaccard参数](https://raw.githubusercontent.com/isEdwardTang/Blog/gh-pages/images/m-pmodel.png)

- FM指数(Fowlkes and Mallows Index，简称FMI):

![FM指数]()

- Rand指数(Rand Index，简称RI):

![Rand指数]()

上述结果在[0,1]区间，值越大越好。

c表示簇的划分，定义如下式子：dist表示两个样本之间的距离，&mu;表示簇C的中心点。则avg表示簇C内样本的平均距离，diam对应簇C内样本减的最远距离，dmin表示两个簇之间最近样本的距离，dcen表示两个簇中心点间的距离。

![聚类簇划分公式]()

基于这些公式，导出常用的性能度量内部指标有以下：

- DB指数(Davies-Bouldin Index，简称DBI)：

![DB指数]()

- Dunn指数(Dunn Index，简称DI)：

![DI指数]()

### 2、距离度量

- 距离度量的性质：非负性、对称性、直递性(三角不等式)。

- 对于有序距离，常用闵可夫斯基距离：

![闵可夫斯基距离]()

当p趋于无穷时得到切比雪夫距离，当p=2时得到欧式距离，p=1时得到曼哈顿距离。

- 对于无序距离，可采用VDM距离：

![VDM距离]()

- 常使用闵可夫斯基距离和VDM距离结合处理混合属性：

![混合属性距离]()

- 对于样本空间中不同属性的重要性不同时，可使用加权距离

## 二、原型聚类算法

原型聚类算法先对原型初始化，然后对原型进行迭代更新求解。

### 1、k均值算法

### 2、学习向量量化

### 3、高斯混合聚类

## 三、密度聚类

## 四、层次聚类



